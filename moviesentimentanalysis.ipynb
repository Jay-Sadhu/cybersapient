{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM50OW5LfXkB",
        "outputId": "233727e5-3c87-4d50-aaec-ef6d10511914"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgXJU-ni_z8-",
        "outputId": "ebcbdf37-65dd-4f55-f02b-dd62dc8f9b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8964\n",
            "Example Text: one reviewers mentioned watching oz episode hooked right exactly happened br br first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use br br called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home many aryans muslims gangstas latinos christians italians irish scuffles death stares dodgy dealings shady agreements never far br br would say main appeal show due fact goes shows would dare forget pretty pictures painted mainstream audiences forget charm forget romance oz mess around first episode ever saw struck nasty surreal could say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards sold nickel inmates kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side\n",
            "Summarized Text: one reviewers mentioned watching oz episode hooked right exactly happened br br first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use br br called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home many aryans muslims gangstas latinos christians italians irish scuffles death stares dodgy dealings shady agreements never far br br would say main appeal show due fact goes shows would dare forget pretty pictures painted mainstream audiences forget charm forget romance oz mess around first episode ever saw struck nasty surreal could say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards sold nickel inmates kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side\n",
            "Translated Text: Un critique a mentionné que regarder un épisode d'Oz accroché à droite s'est produit exactement Br Br Br First Thing a frappé la brutalité des scènes sans faille violence de violence à droite GO TRUST Trust Show Faint Timid Show tire Punches Regards Drugs Violence Sex Hardcore Utilisation classique Br Br Called Oz surnom donné Oswald Maximum Security State Penitentary State PenitentaryFocus principalement de la section expérimentale de la ville émeraude Cellules de prison Fronts de verre face à l'intérieur de la vie privée élevée à haut programme Em City Home de nombreux aryans musulmans gangstas Latinos chrétiens italiens irlandais éraflures Death RegoresLes images peintes au public grand public oublient le charme oublier la romance Oz Mess autour du premier épisode jamais vu frappé de méchante surréaliste pourrait dire Ready Watted Development Taste Oz s'est habitué à des niveaux de violence graphique Hauts à la violence graphique Injustice Crooked Guards Vendu les détenus nickels Kill OrdreDûre manque de compétences en rue Expérience en prison en regardant Oz peut devenir confortable\n",
            "Sentiment: positive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "from googletrans import Translator\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/IMDB Dataset.csv')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
        "    cleaned_text = ' '.join(tokens)\n",
        "    return cleaned_text\n",
        "\n",
        "train_data['cleaned_review'] = train_data['review'].apply(preprocess_text)\n",
        "test_data['cleaned_review'] = test_data['review'].apply(preprocess_text)\n",
        "\n",
        "# Train sentiment analysis model\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_features = vectorizer.fit_transform(train_data['cleaned_review'])\n",
        "test_features = vectorizer.transform(test_data['cleaned_review'])\n",
        "\n",
        "sentiment_model = LogisticRegression()\n",
        "sentiment_model.fit(train_features, train_data['sentiment'])\n",
        "\n",
        "# Predict sentiment for the test dataset\n",
        "predictions = sentiment_model.predict(test_features)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_data['sentiment'], predictions)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Add summarization\n",
        "\n",
        "\n",
        "def summarize_text(text):\n",
        "    # Initialize the parser and tokenizer\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "\n",
        "    # Initialize the summarizer (LSA)\n",
        "    summarizer = LsaSummarizer()\n",
        "\n",
        "    # Summarize the document and get the summary sentences\n",
        "    summary_sentences = summarizer(parser.document, 1)  # Summarize to 1 sentence\n",
        "\n",
        "    # Join the summary sentences into a single string\n",
        "    summarized = \" \".join([str(sentence) for sentence in summary_sentences])\n",
        "\n",
        "    return summarized\n",
        "\n",
        "# Add translation\n",
        "def translate_text(text, target_lang):\n",
        "    translator = Translator()\n",
        "    translated = translator.translate(text, dest=target_lang)\n",
        "    return translated.text\n",
        "\n",
        "# Perform sentiment analysis, summarization, and translation\n",
        "example_text = train_data['cleaned_review'][0]\n",
        "summarized_text = summarize_text(example_text)\n",
        "translated_text = translate_text(example_text, 'fr')\n",
        "\n",
        "sentiment = sentiment_model.predict(vectorizer.transform([example_text]))[0]\n",
        "\n",
        "print(\"Example Text:\", example_text)\n",
        "print(\"Summarized Text:\", summarized_text)\n",
        "print(\"Translated Text:\", translated_text)\n",
        "print(\"Sentiment:\", sentiment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtkND7vYoeFc",
        "outputId": "61e060b8-c678-435a-8553-816bde7b5408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a movie review (or 'exit' to quit): one reviewers mentioned watching oz episode hooked right exactly happened br br first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use br br called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home many aryans muslims gangstas latinos christians italians irish scuffles death stares dodgy dealings shady agreements never far br br would say main appeal show due fact goes shows would dare forget pretty pictures painted mainstream audiences forget charm forget romance oz mess around first episode ever saw struck nasty surreal could say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards sold nickel inmates kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side\n",
            "The review is positive.\n",
            "Enter a movie review (or 'exit' to quit): exit\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load the IMDB dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/IMDB Dataset.csv')\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
        "    cleaned_text = ' '.join(tokens)\n",
        "    return cleaned_text\n",
        "\n",
        "data['cleaned_review'] = data['review'].apply(preprocess_text)\n",
        "\n",
        "# Train sentiment analysis model\n",
        "vectorizer = TfidfVectorizer()\n",
        "features = vectorizer.fit_transform(data['cleaned_review'])\n",
        "\n",
        "sentiment_model = LogisticRegression()\n",
        "sentiment_model.fit(features, data['sentiment'])\n",
        "\n",
        "# Function to classify user input\n",
        "def classify_review(review):\n",
        "    cleaned_review = preprocess_text(review)\n",
        "    feature = vectorizer.transform([cleaned_review])\n",
        "    prediction = sentiment_model.predict(feature)[0]\n",
        "    return prediction\n",
        "\n",
        "# Interactive component to get user input and classify it\n",
        "while True:\n",
        "    user_input = input(\"Enter a movie review (or 'exit' to quit): \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    sentiment = classify_review(user_input)\n",
        "    if sentiment == 'positive':\n",
        "        print(\"The review is positive.\")\n",
        "    else:\n",
        "        print(\"The review is negative.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}